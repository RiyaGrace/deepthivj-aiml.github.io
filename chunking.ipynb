{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHUNKING-TASK2**\n",
    "=================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammer=\"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp=nltk.RegexpParser(grammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('pleased', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('know', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('he', 'PRP'),\n",
       " ('applied', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('concepts', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('internship', 'NN'),\n",
       " ('extensively', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('build', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('professional', 'JJ'),\n",
       " ('tool', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('Intellect', 'NNP'),\n",
       " ('Design', 'NNP'),\n",
       " ('Arena', 'NNP')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"I was pleased to know that he applied the concepts in his internship extensively to build a professional tool for Intellect Design Arena\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=cp.parse(nltk.pos_tag(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  I/PRP\n",
      "  was/VBD\n",
      "  pleased/JJ\n",
      "  to/TO\n",
      "  know/VB\n",
      "  that/IN\n",
      "  he/PRP\n",
      "  applied/VBD\n",
      "  the/DT\n",
      "  concepts/NNS\n",
      "  in/IN\n",
      "  his/PRP$\n",
      "  internship/NN\n",
      "  extensively/RB\n",
      "  to/TO\n",
      "  build/VB\n",
      "  a/DT\n",
      "  professional/JJ\n",
      "  tool/NN\n",
      "  for/IN\n",
      "  Intellect/NNP\n",
      "  Design/NNP\n",
      "  Arena/NNP)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**chunking to find the name of the candidate**\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for doc 1\n",
    "#chunk having name\n",
    "grammer=\"NAME: {<IN|TO><NN|VB><IN>?<NNP>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp=nltk.RegexpParser(grammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = nltk.word_tokenize(\"TO WHOMSOEVER IT MAY CONCERN I am pleased to recommend MrXX for an MS in Computer Science at your esteemed university. I have known him since his second year. He was my student in the 3rd semester (2nd year), where I taught him the course of Database Management Systems. I first got to know X in the course of Database Management Systems, CSE-2004. In the first week of the course, I was surprised to know that X, an Electronics and Instrumentation student, had taken up a computer science core course. Initially I was doubtful about a non-CS student’s approach and grasp of the subject, but he adapted to it as naturally as a fish to water. By the time the course came to an end, he had proved his mettle. I observed that X had a keen interest and was fully involved in the course when I saw his performances during the Lab sessions, where he would be able to grasp new concepts such as query formation and joins. He has been highly active in the technical scene of our college too with him organizing many events.As a part of the course, students are required to develop a project, with a fully functional Database System consisting of the concepts learnt throughout the semester. Despite X not being from a computer science background, his project did not languish. He went above and beyond to make a professional database design, which included an ‘Auto-Increment’ feature using a PL/SQL sequence written by him, bulk insertion into the table and other features.I was pleased to know that he applied the concepts in his internship extensively to build a professional tool for Intellect Design Arena. He designed this tool to make the process of configuring a Logical Data Model easier and much faster. It consisted of a User Interface (UI) that can replicate back-end tasks such as inserting data in a database at the click of a button. His task was cut out for him as the tool was being built for J.P. Morgan Chase as a client and hence there was no room for error. I am proud to say that the tool, which he built over a course of two months, was pushed to production at the end of his internship.X makes a strong candidate for your Master's program majoring in Computer Science. His proposed candidature has my endorsement without any reservations whatsoever. \")\n",
    "#nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('pleased', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('recommend', 'VB'),\n",
       " ('MrXX', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('MS', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('Computer', 'NNP'),\n",
       " ('Science', 'NNP'),\n",
       " ('at', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('esteemed', 'FW'),\n",
       " ('university', 'NN')]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"I am pleased to recommend MrXX for an MS in Computer Science at your esteemed university\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=cp.parse(nltk.pos_tag(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  I/PRP\n",
      "  am/VBP\n",
      "  pleased/JJ\n",
      "  (NAME to/TO recommend/VB MrXX/NNP)\n",
      "  for/IN\n",
      "  an/DT\n",
      "  MS/NNP\n",
      "  in/IN\n",
      "  Computer/NNP\n",
      "  Science/NNP\n",
      "  at/IN\n",
      "  your/PRP$\n",
      "  esteemed/FW\n",
      "  university/NN)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MrXX\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "for vp in list(result.subtrees(filter=lambda x: x.label()=='NAME')):\n",
    "        test.append(\" \".join([i[0] for i in vp.leaves() if len(vp.leaves()) >= 2]))\n",
    "        for i in vp.leaves():\n",
    "            name=i\n",
    "        print(i[0])\n",
    "\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('happy', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('write', 'VB'),\n",
       " ('this', 'DT'),\n",
       " ('letter', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('recommendation', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('AAA', 'NNP'),\n",
       " ('who', 'WP'),\n",
       " ('intends', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('pursue', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('Master', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('degree', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('prestigious', 'JJ'),\n",
       " ('university', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for doc 2 finding name of the candidate\n",
    "textdoc2 = nltk.word_tokenize(\"I am happy to write this letter of recommendation for AAA who intends to pursue a Master's degree at your prestigious university.\")\n",
    "nltk.pos_tag(textdoc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunk having name\n",
    "grammer=\"NAME: {<IN|TO><NN|VB><IN>?<NNP>}\"\n",
    "cp=nltk.RegexpParser(grammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  I/PRP\n",
      "  am/VBP\n",
      "  happy/JJ\n",
      "  to/TO\n",
      "  write/VB\n",
      "  this/DT\n",
      "  letter/NN\n",
      "  (NAME of/IN recommendation/NN for/IN AAA/NNP)\n",
      "  who/WP\n",
      "  intends/VBZ\n",
      "  to/TO\n",
      "  pursue/VB\n",
      "  a/DT\n",
      "  Master/NN\n",
      "  's/POS\n",
      "  degree/NN\n",
      "  at/IN\n",
      "  your/PRP$\n",
      "  prestigious/JJ\n",
      "  university/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "result=cp.parse(nltk.pos_tag(textdoc2))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAA\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "for vp in list(result.subtrees(filter=lambda x: x.label()=='NAME')):\n",
    "        test.append(\" \".join([i[0] for i in vp.leaves() if len(vp.leaves()) >= 2]))\n",
    "        for i in vp.leaves():\n",
    "            name=i\n",
    "        print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.pos_tag(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text2 = nltk.word_tokenize(\"he was very quick to point out that this forms the basis for numerous real-world applications such as spell check and autocomplete. He is also a keen observer often pointing out the mistakes even in his work.During the time that I have known him, he had encountered various.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**named entity recognition**\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#named entity\n",
    "chunks=nltk.ne_chunk(nltk.pos_tag(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities={}\n",
    "for chunk in chunks:\n",
    "    if type(chunk) is nltk.Tree:\n",
    "        t=''.join(c[0] for c in chunk.leaves())\n",
    "        entities[t]=chunk.label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MrXX': 'ORGANIZATION', 'ComputerScience': 'ORGANIZATION'}\n"
     ]
    }
   ],
   "source": [
    "#named entities\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**chunking for extracting experiance**\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiance in\n",
    "#defining regular expression\n",
    "grammer=\"experiance: {<NNP>+}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('pleased', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('know', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('he', 'PRP'),\n",
       " ('applied', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('concepts', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('internship', 'NN'),\n",
       " ('extensively', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('build', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('professional', 'JJ'),\n",
       " ('tool', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('Intellect', 'NNP'),\n",
       " ('Design', 'NNP'),\n",
       " ('Arena', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizing\n",
    "text3 = nltk.word_tokenize(\"I was pleased to know that he applied the concepts in his internship extensively to build a professional tool for Intellect Design Arena.\")\n",
    "nltk.pos_tag(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp=nltk.RegexpParser(grammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=cp.parse(nltk.pos_tag(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  I/PRP\n",
      "  was/VBD\n",
      "  pleased/JJ\n",
      "  to/TO\n",
      "  know/VB\n",
      "  that/IN\n",
      "  he/PRP\n",
      "  applied/VBD\n",
      "  the/DT\n",
      "  concepts/NNS\n",
      "  in/IN\n",
      "  his/PRP$\n",
      "  internship/NN\n",
      "  extensively/RB\n",
      "  to/TO\n",
      "  build/VB\n",
      "  a/DT\n",
      "  professional/JJ\n",
      "  tool/NN\n",
      "  for/IN\n",
      "  (experiance Intellect/NNP Design/NNP Arena/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
